{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distilled ProSST Scoring Notebook\n",
        "\n",
        "This notebook demonstrates how to:\n",
        "1. Load a protein sequence from a FASTA file.\n",
        "2. Quantize a PDB structure.\n",
        "3. Run ProSST inference.\n",
        "4. Score mutational effects from a CSV of mutants.\n",
        "\n",
        "Adjust the file paths in **Step 2** to your own sequence, PDB, and CSV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/typing.py:72: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /opt/conda/envs/worker/lib/python3.12/site-packages/torch_scatter/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
            "/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/typing.py:83: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /opt/conda/envs/worker/lib/python3.12/site-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
            "/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/typing.py:99: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /opt/conda/envs/worker/lib/python3.12/site-packages/torch_spline_conv/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(\n",
            "/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /opt/conda/envs/worker/lib/python3.12/site-packages/torch_sparse/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb\n",
            "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "/opt/conda/envs/worker/lib/python3.12/site-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spearmanr\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForMaskedLM, AutoTokenizer\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprosst\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstructure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdbQuantizer\n",
            "File \u001b[0;32m/worker/ProSST/prosst/structure/quantizer.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mBio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mSeqUtils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m seq1\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Batch, Data\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_scatter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scatter_mean, scatter_sum, scatter_max\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/__init__.py:13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/datasets/__init__.py:101\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msbm_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomPartitionGraphDataset\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmixhop_synthetic_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MixHopSyntheticDataset\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainer_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExplainerDataset\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfection_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InfectionDataset\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mba2motif_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BA2MotifDataset\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/datasets/explainer_dataset.py:9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphGenerator\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmotif_generator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MotifGenerator\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explanation\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mExplainerDataset\u001b[39;00m(InMemoryDataset):\n\u001b[1;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Generates a synthetic dataset for evaluating explainabilty algorithms,\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m    as described in the `\"GNNExplainer: Generating Explanations for Graph\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    Neural Networks\" <https://arxiv.org/abs/1903.03894>`__ paper.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m            (default: :obj:`None`)\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/explain/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExplainerConfig, ModelConfig, ThresholdConfig\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplanation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explanation, HeteroExplanation\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explainer\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetric\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/explain/algorithm/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ExplainerAlgorithm\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdummy_explainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DummyExplainer\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgnn_explainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GNNExplainer\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/explain/algorithm/base.py:14\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explanation, HeteroExplanation\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     ExplainerConfig,\n\u001b[1;32m     11\u001b[0m     ModelConfig,\n\u001b[1;32m     12\u001b[0m     ModelReturnType,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessagePassing\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EdgeType, NodeType\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m k_hop_subgraph\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/nn/__init__.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataParallel\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mto_hetero_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_hetero\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mto_hetero_with_bases_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_hetero_with_bases\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mto_fixed_size_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_fixed_size\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PositionalEncoding, TemporalEncoding\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/nn/to_hetero_with_bases_transformer.py:9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Module, Parameter\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessagePassing\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdense\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Linear\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfx\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transformer\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/nn/conv/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcugraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msage_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CuGraphSAGEConv\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GraphConv\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgravnet_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GravNetConv\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgated_graph_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GatedGraphConv\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mres_gated_graph_conv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResGatedGraphConv\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_geometric/nn/conv/gravnet_conv.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptTensor, PairOptTensor, PairTensor\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_cluster\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m knn\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m     knn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch_cluster/__init__.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m spec \u001b[38;5;241m=\u001b[39m cuda_spec \u001b[38;5;129;01mor\u001b[39;00m cpu_spec\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/site-packages/torch/_ops.py:933\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    928\u001b[0m path \u001b[38;5;241m=\u001b[39m _utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m    929\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
            "File \u001b[0;32m/opt/conda/envs/worker/lib/python3.12/ctypes/__init__.py:379\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
            "\u001b[0;31mOSError\u001b[0m: /opt/conda/envs/worker/lib/python3.12/site-packages/torch_cluster/_version_cpu.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSsb"
          ]
        }
      ],
      "source": [
        "# Step 1: Imports\n",
        "import torch\n",
        "import pandas as pd\n",
        "from Bio import SeqIO\n",
        "from scipy.stats import spearmanr\n",
        "from transformers import AutoModelForMaskedLM, AutoTokenizer\n",
        "from prosst.structure.quantizer import PdbQuantizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 2: Define file paths\n",
        "# Adjust these to point to your own files.\n",
        "FASTA_FILE = 'example_data/GRB2_HUMAN_Faure_2021.fasta'  # Your sequence file\n",
        "PDB_FILE = 'example_data/GRB2_HUMAN_Faure_2021.pdb'       # Your PDB file\n",
        "MUT_CSV = 'example_data/GRB2_HUMAN_Faure_2021.csv'       # CSV file with mutants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 3: Load ProSST model & tokenizer\n",
        "If you are behind a corporate firewall or in a region that cannot access Hugging Face, you may need to configure a proxy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = AutoModelForMaskedLM.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"AI4Protein/ProSST-2048\", trust_remote_code=True)\n",
        "\n",
        "processor = PdbQuantizer()  # For converting PDB to quantized structural tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 4: Read the protein sequence and quantize the PDB\n",
        "We will:\n",
        "1. Read the sequence from FASTA.\n",
        "2. Quantize the structure from PDB.\n",
        "3. Offset the structure tokens by `+3` for `[CLS]`, `[SEP]`, `[PAD]` handling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Read sequence\n",
        "residue_sequence = str(SeqIO.read(FASTA_FILE, 'fasta').seq)\n",
        "\n",
        "# Quantize structure\n",
        "structure_sequence = processor(PDB_FILE)\n",
        "\n",
        "# Offset structure codes for special tokens\n",
        "structure_sequence_offset = [s + 3 for s in structure_sequence]\n",
        "\n",
        "print(f\"Residue sequence length: {len(residue_sequence)}\")\n",
        "print(f\"Quantized structure length: {len(structure_sequence)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 5: Prepare model input tensors\n",
        "We'll tokenize the residue sequence, then build the input IDs for the structure (including `[CLS] = 1` and `[SEP] = 2`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_res = tokenizer([residue_sequence], return_tensors='pt')\n",
        "input_ids = tokenized_res['input_ids']\n",
        "attention_mask = tokenized_res['attention_mask']\n",
        "\n",
        "# Build structure input: [CLS] + structure_sequence + [SEP]\n",
        "structure_input_ids = torch.tensor(\n",
        "    [1, *structure_sequence_offset, 2],  # 1 = [CLS], 2 = [SEP]\n",
        "    dtype=torch.long\n",
        ").unsqueeze(0)\n",
        "\n",
        "print(\"Sequence input size:\", input_ids.shape)\n",
        "print(\"Structure input size:\", structure_input_ids.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6: Run inference on the sequence\n",
        "We'll get the logits (logits across the vocabulary for each residue position)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        ss_input_ids=structure_input_ids\n",
        "    )\n",
        "\n",
        "# We'll convert logits to log probabilities.\n",
        "# Note that outputs.logits has shape: [batch, seq_len, vocab_size].\n",
        "# The model's input has 1 extra token on the left and right, so slice [1:-1].\n",
        "logits = torch.log_softmax(outputs.logits[:, 1:-1], dim=-1).squeeze()\n",
        "print(\"Logits shape (positions x vocabulary):\", logits.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 7: Score your mutants\n",
        "The CSV file should have a column `mutant` that describes the mutations (e.g. `A100V` or `A100V:M101T`).\n",
        "We'll parse each mutation, subtract the log probability of the wild-type amino acid from the log probability of the mutant, and sum if there are multiple substitutions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(MUT_CSV)\n",
        "mutants = df['mutant'].tolist()\n",
        "\n",
        "vocab = tokenizer.get_vocab()\n",
        "pred_scores = []\n",
        "\n",
        "for mutant in mutants:\n",
        "    total_mut_score = 0.0\n",
        "    # Handle compound mutants like \"A100V:M101T\"\n",
        "    for sub_mutant in mutant.split(\":\"):\n",
        "        wt_aa = sub_mutant[0]\n",
        "        pos   = int(sub_mutant[1:-1]) - 1  # zero-based index\n",
        "        mt_aa = sub_mutant[-1]\n",
        "        \n",
        "        # Score = logP(mutant) - logP(wt)\n",
        "        delta = logits[pos, vocab[mt_aa]] - logits[pos, vocab[wt_aa]]\n",
        "        total_mut_score += delta.item()\n",
        "    pred_scores.append(total_mut_score)\n",
        "\n",
        "df['PredictedScore'] = pred_scores\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### (Optional) Step 8: Compute Spearman correlation\n",
        "If your CSV contains an experimental DMS_score or another numeric metric, you can calculate the correlation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'DMS_score' in df.columns:\n",
        "    corr = spearmanr(df['PredictedScore'], df['DMS_score'])\n",
        "    print(\"Spearman correlation:\", corr)\n",
        "else:\n",
        "    print(\"No 'DMS_score' column found; skipping correlation calculation.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
