FROM nvidia/cuda:12.2.0-devel-ubuntu20.04

COPY backend/requirements.txt /backend/
COPY worker/scripts/setup.sh /scripts/setup.sh
RUN /scripts/setup.sh

# Install special requirements.
RUN /opt/conda/envs/worker/bin/python -m pip install boltz==0.4.1

# # Chat suggested this, for when on a weird network.
# RUN echo "nameserver 8.8.8.8" > /etc/resolv.conf && \
#     echo "nameserver 8.8.4.4" >> /etc/resolv.conf

# # Download the huggingface models...
# RUN HF_HUB_ENABLE_HF_TRANSFER=1 /opt/conda/envs/worker/bin/huggingface-cli download \
#   --resume-download \
#   --local-dir /hf-cache/ \
#   boltz-community/boltz-1 boltz1_conf.ckpt ccd.pkl

# Copy application code.
COPY backend/ /backend/
COPY worker/*.sh /worker/
COPY worker/*.py /worker/
COPY worker/docking/* /worker/docking/

# Gotta set the workdir so that the entrypoint can find the rq_worker_main.py.
WORKDIR /backend/src

# Make sure to use the exec form of ENTRYPOINT, rather than the shell
# form, so that SIGTERM gets propagated to rq.
# https://medium.com/@tasdikrahman/handling-signals-for-applications-running-in-kubernetes-dc6537f9b542
# https://docs.docker.com/engine/reference/builder/#entrypoint
ENTRYPOINT ["/opt/conda/envs/worker/bin/flask"]