FROM nvidia/cuda:12.2.0-devel-ubuntu20.04

COPY worker/scripts/base_setup.sh /scripts/base_setup.sh
RUN /scripts/base_setup.sh

COPY backend/requirements.txt /backend/
COPY worker/scripts/conda_env_setup.sh /scripts/conda_env_setup.sh
RUN /scripts/conda_env_setup.sh

# Install special requirements.
#
# We want no-deps so that the boltz install doesn't mess with our carefully
# curated package versions created in setup.sh
#
# It would be... very sane to allow pip to install these dependencies for us...
# Except that pytorch is so finicky.
#
# To future authors: You can try replacing all of the below with
#   pip install boltz==1.0.0
# and see if you have an easier way to solve the torch versioning problem.
# RUN /opt/conda/bin/conda install -y -n worker -c conda-forge mamba
# RUN /opt/conda/envs/worker/bin/mamba install -y -n worker -c conda-forge \
#       lightning=2.2.* \
#       torchmetrics=1.3.* \
#       rdkit>=2024.3.2 \
#       numba==0.59.* \
#       && /opt/conda/bin/conda clean -afq

# RUN /opt/conda/envs/worker/bin/python -m pip install \
#     boltz==1.0.0 \
#     dm-tree==0.1.8 \
#     einops==0.8.0 \
#     einx==0.3.0 \
#     fairscale==0.4.13 \
#     mashumaro==3.14 \
#     modelcif==1.2 \
#     wandb==0.18.7 \
#     trifast==0.1.11 \
#     ihm \
#     --no-deps

# RUN echo "pytorch==2.2.*\ntorchvision==0.17.*\ntorchaudio==2.2.*\npytorch-cuda==12.1\ngpytorch==1.14\nbotorch==0.14.*\nlinear_operator==0.6\npyro-ppl>=1.8.4" > /tmp/constraints.txt
# RUN /opt/conda/envs/worker/bin/python -m pip install boltz==1.0.0 --constraint /tmp/constraints.txt

RUN /opt/conda/bin/conda create -y -n boltzenv python=3.11
# RUN /opt/conda/envs/boltzenv/bin/python -m pip install boltz==1.0.0
RUN /root/.local/bin/uv pip install --python /opt/conda/envs/boltzenv/bin/python boltz==2.1.1
# RUN /opt/conda/envs/boltzenv/bin/python -m pip install boltz==2.2.0

# # Chat suggested this, for when on a weird network.
# RUN echo "nameserver 8.8.8.8" > /etc/resolv.conf && \
#     echo "nameserver 8.8.4.4" >> /etc/resolv.conf

# # Download the huggingface models...
# RUN HF_HUB_ENABLE_HF_TRANSFER=1 /opt/conda/envs/worker/bin/huggingface-cli download \
#   --resume-download \
#   --local-dir /hf-cache/ \
#   boltz-community/boltz-1 boltz1_conf.ckpt ccd.pkl

# Copy application code.
COPY backend/ /backend/
COPY worker/*.sh /worker/
COPY worker/*.py /worker/
COPY worker/docking/* /worker/docking/

# Gotta set the workdir so that the entrypoint can find the rq_worker_main.py.
WORKDIR /backend

# Make sure to use the exec form of ENTRYPOINT, rather than the shell
# form, so that SIGTERM gets propagated to rq.
# https://medium.com/@tasdikrahman/handling-signals-for-applications-running-in-kubernetes-dc6537f9b542
# https://docs.docker.com/engine/reference/builder/#entrypoint
ENTRYPOINT ["/opt/conda/envs/worker/bin/flask"]
